{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681e2f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14f41bc70b37478d85512f8e81bd2011",
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# ADD ADDITIONAL IMOPRTS IN ASSIGNMENT CELLS\n",
    "\n",
    "# Notebook configs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import HTML\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf2ee0e-0423-4348-990f-4913e9ea019d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6586315e90c8356c876719cf576d4fd3",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# GML Mini-Challenge 1 - HS 2024\n",
    "\n",
    "**Ausgabe:** Montag 14.10.2024  \n",
    "**Abgabe:** Montag 11.11.2024 23:59 Uhr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-boutique",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78c5558c8657e623e892a821c7b58ba8",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Vorgaben zu Umsetzung und Abgabe\n",
    "\n",
    "- Die Algorithmen müssen auf der Basis von Array Operationen selber implementiert werden.\n",
    "- Der Code muss lauffähig sein bei Ausführung im aktuellen Docker-Container zum gml Repo oder auf JHub. \n",
    "- Es darf kein Code ausgelagert werden, i.e. sämtlicher Code muss sich im Notebook befinden.\n",
    "- Sämtliche Plots sind komplett beschriftet (Achsen, Labels, Überschrift, Colorbar, ..), so dass der Plot ohne den Code zu konsultieren, verstanden werden kann.\n",
    "- Als **Abgabe** zählt der letzte Commit vor Abgabetermin in in deinem Fork des Repos.  \n",
    "- **Bitte lösche, kopiere, dupliziere, splitte und verschiebe die vorhandenen Zellen nicht**. Dies führt zu Problemen bei der Korrektur. Du darfst aber beliebig viele weitere Zellen hinzufügen (nur via **insert new cell**).\n",
    "- Laufzeit vom Notebook: Das gesamte Notebook sollte in weniger als 1 Stunde ausgeführt werden können.\n",
    "\n",
    "Für die Erarbeitung der Lösung darf unter Studierenden zusammengearbeitet werden.  \n",
    "Die Zusammenarbeit ist dabei aber auf konzeptionelle und algorithmische Fragen und Verständnisaspekte beschränkt.  \n",
    "\n",
    "**Es darf kein Code oder Text von anderen oder vom Internet kopiert werden.**\n",
    "\n",
    "\n",
    "### Python Module\n",
    "\n",
    "Neben den Python-Basismodulen darfst du die folgenden Module immer benutzen: `numpy`, `pandas`, `matplotlib`, `seaborn`,  `tqdm` (für Progress-Bars).\n",
    "\n",
    "Du darfst auch generell [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing), [sklearn.model_selection](https://scikit-learn.org/stable/model_selection.html), [sklearn.pipeline](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.pipeline) und [sklearn.compose](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.compose) verwenden.\n",
    "\n",
    "Weitere Module darfst du nur verwenden wenn dies ausdrücklich erwähnt oder bereits vorgegeben ist in der Code-Cell.\n",
    "\n",
    "\n",
    "## Bewertung\n",
    "\n",
    "Bewertet wird:\n",
    "\n",
    "- Vollständigkeit (Code, Text)\n",
    "- Korrektheit (Code, Text)\n",
    "- Implementation (z.B. Vektorisierung der Operationen, Scikit-Learn API, Visualisierungen, Lesbarkeit Code/Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3cff4a-3730-4b6f-bfaa-625f69832b13",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "455923962dc655f9a3f3729b91084cf8",
     "grade": false,
     "grade_id": "introduction",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Einleitung\n",
    "\n",
    "Biologen haben einen umfangreichen Datensatz zu Schalentieren gesammelt. Dabei haben sie die Tiere zerlegt, vermessen und verschiedene Messgrössen erfasst. Das Alter eines solchen Schalentiers kann, ähnlich wie bei Bäumen, über das Zählen von Ringen, die im Schalenquerschnitt ersichtlich sind, bestimmt werden. Dabei ergibt sich das Alter des Tieres als Anzahl Ringe + 1.5. Jahre. Dieser Vorgang ist aber sehr zeitaufwendig. Aus dem vorliegenden Datensatz möchten die Biologen nun untersuchen, ob es möglich ist, das Alter der Tiere aus den anderen, einfach zu erfassenden Messgrössen abzuschätzen, um in Zukunft auf das Zählen der Schalenringe verzichten zu können.\n",
    "\n",
    "Auf jeder Zeile des vorliegenden Datensatzes sind die Messgrössen eines Schalentiers gegeben. Die Spalten sind wie folgt zu verstehen:\n",
    "\n",
    "| Spalte        | Erklärung                                                      | Einheit    |\n",
    "|-------------- |----------------------------------------------------------------| -----------|\n",
    "| geschlecht    | Das Geschlecht des Tieres.                                     |            |\n",
    "| laenge        | Die grösste Spanne gemessen über die Schale hinweg.            | mm         |\n",
    "| breite        | Die Spanne gemessen senkrecht zur Länge.                       | mm         |\n",
    "| hoehe         | Die Spanne von unten nach oben gemessen, mit lebendem Inhalt.  | mm         |\n",
    "| gew_tot       | Gesamtgewicht                                                  | g          |\n",
    "| gew_f         | Gewicht des Fleisches des Schalentiers                         | g          |\n",
    "| gew_i         | Gewicht der Innereien                                          | g          |\n",
    "| gew_s         | Gewicht der Schale                                             | g          |\n",
    "| ringe         | Anzahl der gezählten Ringe; +1.5 ergibt das Alter in Jahren    |            |\n",
    "\n",
    "Wir wollen nun helfen zu verstehen, wie gut wir das Alter der Schalentiere vorhersagen können, unter Verwendung dieser Variablen, ohne die Anzahl der Ringe zu kennen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-chambers",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2985ac137df8fe10466a3f76e04085ac",
     "grade": false,
     "grade_id": "aufgabe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 1 (8 Punkte)\n",
    "\n",
    "Bevor wie einen Datensatz modellieren wollen wir diesen stets mit Explorativer Datenanalyse kennenlernen.  \n",
    "Dabei legen wir besonderes Augenmerk auf die für unsere Modellierungsaufgabe relevanten Aspekte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeceb2c6-0b40-439e-8d35-32354be126ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd16a2e3ae3886b6d2e57fef33c740f4",
     "grade": false,
     "grade_id": "task1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 1 a\n",
    "\n",
    "Unternimm die die folgenden Schritte:\n",
    "    \n",
    "- Lese den Datensatz `schalentiere_train.csv` ein und verschaffe dir einen groben Überblick.\n",
    "- Berechne und zeige wichtige statistische Kennzahlen.\n",
    "- Visualisiere jede Variable mit einem sinnvollen Plot. Berücksichtige dabei die Aufgabenstellung.\n",
    "\n",
    "Versuche abzuschätzen, wie gut die Vorhersage des Alters gelingen könnte, welche Variablen wichtig sein könnten und wie man Variablen allenfalls präprozessieren muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-cloud",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "816f775f470da1e1607c98ce8b9ac280",
     "grade": true,
     "grade_id": "antwort1a",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geschlecht</th>\n",
       "      <th>laenge</th>\n",
       "      <th>breite</th>\n",
       "      <th>hoehe</th>\n",
       "      <th>gew_tot</th>\n",
       "      <th>gew_f</th>\n",
       "      <th>gew_i</th>\n",
       "      <th>gew_s</th>\n",
       "      <th>ringe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.0650</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>0.285</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.175</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.011</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.207</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.250</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geschlecht  laenge  breite  hoehe  gew_tot   gew_f   gew_i  gew_s  ringe\n",
       "0          M   0.625   0.480  0.175   1.0650  0.4865  0.2590  0.285     10\n",
       "1          M   0.480   0.380  0.130   0.6175  0.3000  0.1420  0.175     12\n",
       "2          W   0.200   0.145  0.060   0.0370  0.0125  0.0095  0.011      4\n",
       "3          W   0.505   0.400  0.145   0.7045  0.3340  0.1425  0.207      8\n",
       "4          M   0.500   0.415  0.165   0.6885  0.2490  0.1380  0.250     13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data einlesen\n",
    "import pandas as pd\n",
    "data = pd.read_csv('schalentiere_training.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0229e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laenge</th>\n",
       "      <th>breite</th>\n",
       "      <th>hoehe</th>\n",
       "      <th>gew_tot</th>\n",
       "      <th>gew_f</th>\n",
       "      <th>gew_i</th>\n",
       "      <th>gew_s</th>\n",
       "      <th>ringe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "      <td>3132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.523851</td>\n",
       "      <td>0.407996</td>\n",
       "      <td>0.139735</td>\n",
       "      <td>0.831573</td>\n",
       "      <td>0.359797</td>\n",
       "      <td>0.180614</td>\n",
       "      <td>0.239814</td>\n",
       "      <td>9.921775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.120694</td>\n",
       "      <td>0.099755</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.494657</td>\n",
       "      <td>0.223299</td>\n",
       "      <td>0.109780</td>\n",
       "      <td>0.141134</td>\n",
       "      <td>3.230120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.444375</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.093875</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.796750</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.230750</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.154125</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.329625</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.779500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            laenge       breite        hoehe      gew_tot        gew_f  \\\n",
       "count  3132.000000  3132.000000  3132.000000  3132.000000  3132.000000   \n",
       "mean      0.523851     0.407996     0.139735     0.831573     0.359797   \n",
       "std       0.120694     0.099755     0.043210     0.494657     0.223299   \n",
       "min       0.075000     0.055000     0.000000     0.002000     0.001000   \n",
       "25%       0.450000     0.350000     0.115000     0.444375     0.186000   \n",
       "50%       0.545000     0.425000     0.140000     0.796750     0.334000   \n",
       "75%       0.615000     0.480000     0.165000     1.154125     0.502000   \n",
       "max       0.815000     0.650000     1.130000     2.779500     1.488000   \n",
       "\n",
       "             gew_i        gew_s        ringe  \n",
       "count  3132.000000  3132.000000  3132.000000  \n",
       "mean      0.180614     0.239814     9.921775  \n",
       "std       0.109780     0.141134     3.230120  \n",
       "min       0.000500     0.001500     1.000000  \n",
       "25%       0.093875     0.130000     8.000000  \n",
       "50%       0.171000     0.230750     9.000000  \n",
       "75%       0.253125     0.329625    11.000000  \n",
       "max       0.760000     1.005000    29.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wichtige Kennzahlen\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d9aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3132 entries, 0 to 3131\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   geschlecht  3132 non-null   object \n",
      " 1   laenge      3132 non-null   float64\n",
      " 2   breite      3132 non-null   float64\n",
      " 3   hoehe       3132 non-null   float64\n",
      " 4   gew_tot     3132 non-null   float64\n",
      " 5   gew_f       3132 non-null   float64\n",
      " 6   gew_i       3132 non-null   float64\n",
      " 7   gew_s       3132 non-null   float64\n",
      " 8   ringe       3132 non-null   int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 220.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819e5707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ringe         1.000000\n",
       "gew_s         0.631968\n",
       "breite        0.580289\n",
       "laenge        0.561250\n",
       "gew_tot       0.547450\n",
       "hoehe         0.545808\n",
       "gew_i         0.513120\n",
       "gew_f         0.429565\n",
       "geschlecht         NaN\n",
       "Name: ringe, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Korrelationen\n",
    "data_encoded = data.copy()\n",
    "data_encoded['geschlecht'] = data_encoded['geschlecht'].map({'M': 0, 'F': 1})\n",
    "data_encoded.corr()['ringe'].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1485f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x3000 with 0 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x40006e4e1710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'geschlecht vs Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'geschlecht')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x40006e53a310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'laenge vs Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'laenge')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x40006ef55a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'breite vs Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'breite')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x40006ef8f4d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'hoehe vs Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'hoehe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x40006efce810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'gew_tot vs Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'gew_tot')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x40006efccdd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'gew_f vs Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'gew_f')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x40006efcfe50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'gew_i vs Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'gew_i')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x40006f081bd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'gew_s vs Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'gew_s')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ringe')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "features = [col for col in data.columns if col != \"ringe\"]\n",
    "\n",
    "plt.figure(figsize=(15, 30))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot((len(features) // 2) + 1, 2, i + 1)\n",
    "    plt.scatter(data[feature], data[\"ringe\"])\n",
    "    plt.title(f'{feature} vs Ringe')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Ringe\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558a37c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad76fffa184979553d9ffe48a1946bd5",
     "grade": false,
     "grade_id": "aufgabe1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 1 b\n",
    "\n",
    "Unser Ziel ist es, das Alter der Schalentiere vorherzusagen unter Verwendung der im Datensatz vorhandenen Variablen, ausser der Anzahl Ringe.  \n",
    "Können wir auch direkt die Anzahl Ringe vorhersagen? Warum? Begründe mit Bezugnahme auf ein (regularisiertes) Lineares Modell.\n",
    "\n",
    "Diskutiere deine Einsichten zum Modellieren der Anzahl Ringe auf Basis der Analyse in Aufgabe 1a.\n",
    "\n",
    "Was fällt sonst noch auf in den Daten? Beschreibe und begründe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-portuguese",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7110ecb281577e0a5106f44be9f515db",
     "grade": true,
     "grade_id": "antwort1b",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1. Ja, es ist möglich, die Anzahl der Ringe direkt vorherzusagen, da die Anzahl der Ringe als abhängige Variable in einem Vorhersagemodell verwendet werden kann, wie zum Beispiel ein reguliertes Lineares Modell:\n",
    "\n",
    "- Die dargestellten Scatterplots zeigen eine überwiegend positive lineare Korrelation zwischen den unabhängigen Variablen und der Zielvariable „Ringe“. Das bedeutet, dass ein lineares Modell eine sinnvolle Wahl sein kann, um diese Beziehungen zu modellieren.\n",
    "\n",
    "- Regularisierte lineare Modelle fügen dem Modell eine Strafe für zu große Koeffizienten hinzu. Dies hilft, Overfitting zu verhindern, besonders wenn es Korrelationen zwischen den unabhängigen Variablen gibt oder einige Variablen weniger wichtig für die Vorhersage sind. Die Regularisierung verhindert, dass das Modell zu komplex wird und passt es an, um bessere generalisierte Vorhersagen zu liefern.\n",
    "\n",
    "- Ein lineares Modell ist leicht interpretierbar, da die Koeffizienten anzeigen, wie stark jede unabhängige Variable die Anzahl der Ringe beeinflusst. Bei einem regularisierten Modell können die weniger relevanten Variablen auf nahezu null reduziert werden, was die Interpretation weiter vereinfacht.\n",
    "\n",
    "2. Basierend auf den Scatterplots und der Analyse der Variablen können einige Schlussfolgerungen gezogen werden:\n",
    "\n",
    "- Zwischen dem Geschlecht und den Ringen gibt es keine signifikante lineare Beziehung, da die Verteilung beider Geschlechter ähnlich aussehen. Diese Variable ist daher nicht so relevant für das lineare Modell.\n",
    "\n",
    "- Das Gewicht, besonders das Gewicht der Schale zeigen eine sehr klare lineare positive Tendenz mit den Ringen. Diese Variablen werden also sehr relevant für das lineare Modell.\n",
    "\n",
    "- Die Datenpunkte bei der Variable Höhe zeigen einige Ausreisser, welche das lineare Modell beeinflussen könnten. Dies wird auch anahnd der Statsitiken sichtbar, denn der Mittelwert liegt bei etwa 0.1, der Maximalwert jedoch bei 1.1.\n",
    "\n",
    "- bei einigen Variablen, wie der breite oder dem totalen Gewicht nimmt die Streuung der Datenpunkte bei höherer Ringanzahl zu. Das Model könnte also Schwierigkeiten haben, diese präzise zu erfassen.\n",
    "\n",
    "- Die Verteilung der Anzahl der Ringe scheint relativ breit zu sein (zwischen 5 und 25 Ringen), was auf eine Vielzahl von Altersstufen bei den Schalentiere hinweist. Ein lineares Modell könnte Schwierigkeiten haben, die Ränder dieser Verteilung genau zu modellieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-emperor",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44797ebdc5f83c640b1b5f4f679f4ac9",
     "grade": false,
     "grade_id": "aufgabe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 2 (14 Punkte)\n",
    "\n",
    "In dieser Aufgabe ist es das Ziel eine regularisierte Lineare Regression zu implementieren (_Ridge Regression_) und die Implementation zu validieren.\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "Ridge Regression ist eine regularisierte Form ($L_2$-Regularisierung) der Ordinary Least Squares (OLS) Kostenfunktion für die lineare Regression.  \n",
    "\n",
    "Die Ridge Regression-Kostenfunktion $J(\\mathbf{w})$ für einen Datensatz $\\cal{D}=\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots, (\\mathbf{x}^{(n)}, y^{(n)}) \\}$ mit $n$ Datenpunkten ist:\n",
    "\n",
    "\\begin{align}\n",
    "J(\\mathbf{w}) &= \\frac{1}{2n}\\sum_{i=1}^n (y^{(i)} - \\mathbf{x}^{(i)T}\\mathbf{w})^2 + \\Omega(\\mathbf{w})\n",
    "\\end{align}\n",
    "\n",
    "Wobei die Regularisierung $\\Omega(\\mathbf{w})$ folgendermassen definiert ist:\n",
    "\n",
    "\\begin{align}\n",
    "\\Omega(\\mathbf{w}) &= \\frac{1}{2}\\lambda \\sum_{j=1}^p w_j^2 \n",
    "\\end{align}\n",
    "\n",
    "Der $i$te Datenpunkt $\\mathbf{x}^{(i)}$ ist ein Vektor der Dimensionalität $\\mathbb{R}^{p +1}$: $\\mathbf{x}^{(i)} = \\Big(1, x_1^{(i)}, \\dots , x_p^{(i)}\\Big)$.\n",
    "\n",
    "$\\mathbf{w} = (w_0, \\dots, w_p)$ sind dabei die Modellkoeffizienten, $\\lambda$ ist die Regularisierungsstärke.\n",
    "\n",
    "\n",
    "**Beachte:**\n",
    "\n",
    "- In sklearn wird statt $\\lambda$ jeweils $\\alpha$ `alpha` als Bezeichnung für die Regularisierungsstärke verwendet (wohl weil `lambda` ein reserviertes Wort ist in Python).\n",
    "\n",
    "- Um Gradient Descent umzusetzen, musst du die Kostenfunktion ableiten.\n",
    "\n",
    "- Implementiere alles vektorisiert.\n",
    "\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "\n",
    "Mit _Batch Gradient Descent (BGD)_ berechnet man den Gradienten der Kostenfunktion bezüglich der Modellparameter für jeden _Gradient Descent Step_ mit **allen Datenpunkten**. Damit berechnet man den Gradient exakt. Man kann den Gradienten jedoch auch mit einem Subset der Datenpunkte berechnen und den exakten Gradient damit schätzen. Dadurch verringert sich der Rechenaufwand. Mit _Stochastic Gradient Descent (SGD)_ nimmt man nur **einen, zufällig ausgewählten, Datenpunkt** (deshalb _stochastic_) um den Gradient in jeder Iteration zu schätzen. \n",
    "\n",
    "Implementiere die Optionen `optimization_method=\"bgd\"` und `optimization_method=\"sgd\"` um das Modell wahlweise mit _BGD_ oder _SGD_ zu optimisieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-addition",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d3274f178337bcdd9dfcc8f390576a0",
     "grade": false,
     "grade_id": "aufgabe2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 2a\n",
    "Ergänze die untenstehende Klasse und deren Methoden. Folge der Scikit-Learn API ([Link](https://scikit-learn.org/stable/developers/develop.html)): Das bedeutet im Wesentlichen, dass du die Methoden implementieren sollst, die in der Klasse schon vorgegeben sind.\n",
    "\n",
    "Beachte die in den Doc-Strings spezifizierten Angaben, insbesondere auch die der Shapes der Inputs und Outputs der einzelnen Methoden.\n",
    "\n",
    "Der Estimator soll eine Ridge Regression durchführen. Das Finden der Modell-Koeffizienten soll mit Gradient Descent erfolgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5372f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Self\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class LinearRegression(BaseEstimator):\n",
    "    \"\"\"Linear Regression\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "        epsilon: if norm of gradient falls below epsilon, \n",
    "            gradient descent terminates (disable with negative values)  \n",
    "        max_num_steps: max number of steps for gradient descent\n",
    "        learning_rate: learning rate for gradient descent\n",
    "        optimization_method: one of 'bgd' (batch gradient descent),\n",
    "            'sgd' (stochastic gradient descent)\n",
    "        alpha: regularization strength (lambda)\n",
    "        verbose: whether to print progress during model training (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon: float = -1,\n",
    "        max_num_steps: int = 1000,\n",
    "        learning_rate: float = 0.1,\n",
    "        optimization_method: str = \"bgd\",\n",
    "        alpha: float = 0.0,\n",
    "        verbose: bool = True\n",
    "    ):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.max_num_steps = max_num_steps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimization_method = optimization_method\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        \"\"\"Fit the model coefficients.\n",
    "        Args:\n",
    "            X: input data (n, p)\n",
    "            y: input labels (n, )\n",
    "\n",
    "        Attributes>\n",
    "            w_: model coefficients as 1d array, including bias weight w_0 \n",
    "\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        n, p = X.shape\n",
    "        self.w_ = np.zeros(p + 1)\n",
    "        self.costs_ = []\n",
    "        \n",
    "        for step in tqdm(range(self.max_num_steps)):\n",
    "            if self.optimization_method == \"bgd\":\n",
    "                gradient = self.gradient(X, y)\n",
    "            \n",
    "            elif self.optimization_method == \"sgd\":\n",
    "                i = np.random.randint(0, n)\n",
    "                gradient = self.gradient(X[i:i+1], y[i:i+1])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown optimization method: {self.optimization_method}\")\n",
    "\n",
    "            self.w_ -= self.learning_rate * gradient\n",
    "\n",
    "            cost = self.cost(X, y)\n",
    "            \n",
    "            self.costs_.append(cost)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Step {step}, Cost: {cost}\")\n",
    "\n",
    "            if self.epsilon > 0 and np.linalg.norm(gradient) < self.epsilon:\n",
    "                if self.verbose:\n",
    "                    print(f\"Gradient norm below epsilon, terminating optimization.\")\n",
    "                break\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def gradient(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate Gradient of Cost Function.\n",
    "        \n",
    "        Calculates dJ/dw, while w are the current parameter estimates in self.w_\n",
    "\n",
    "        Args:\n",
    "            X: input data (n, p)\n",
    "            y: input labels (n, )\n",
    "\n",
    "        Returns:\n",
    "            dJ/dw gradient vector (p + 1, )\n",
    "        \"\"\"\n",
    "        X_bias = np.c_[np.ones((X.shape[0], 1)), X] \n",
    "        # OLS gradient\n",
    "        gradient = (1/len(y)) * X_bias.T.dot(X_bias.dot(self.w_) - y) + (self.alpha/len(y)) * self.w_\n",
    "        \n",
    "        assert gradient.ndim == 1\n",
    "        return gradient\n",
    "    \n",
    "    def cost(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Evaluate the Cost Function.\n",
    "\n",
    "        Args:\n",
    "            X: input data (n, p)\n",
    "            y: input labels (n, )\n",
    "\n",
    "        Returns:\n",
    "            total cost\n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "    \n",
    "        cost = (1 / (2 * n)) * np.sum((y - self.predict(X)) ** 2)\n",
    "        # add L2 regularization\n",
    "        cost += (self.alpha / 2) * np.sum(self.w_[:-1] ** 2)\n",
    "        \n",
    "        assert isinstance(cost, float)\n",
    "        return cost\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate Predictions.\n",
    "\n",
    "        Args:\n",
    "            X: input Data (n, p)\n",
    "            \n",
    "        Returns:\n",
    "            Predictions (n, )\n",
    "        \"\"\"\n",
    "        X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        pred = X_bias @ self.w_\n",
    "        \n",
    "        assert pred.ndim == 1, \"Predictions should be 1D\"\n",
    "        return pred\n",
    "\n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Calculate R^2\n",
    "        \n",
    "        See: https://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "\n",
    "        Args:\n",
    "            X: Input Data (n, p)\n",
    "            y: Input Labels (n, )\n",
    "        \n",
    "        Returns:\n",
    "            R^2\n",
    "        \"\"\"\n",
    "        Rsquare = 1 - np.sum((y - self.predict(X))**2) / np.sum((y - np.mean(y))**2)\n",
    "        \n",
    "        assert isinstance(Rsquare, float)\n",
    "        return Rsquare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2bd0b-5d39-40d9-b943-44fd8a9a4b45",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16af6f71501ad913e6a39da814164e32",
     "grade": false,
     "grade_id": "info2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2b\n",
    "Die folgende Zelle enthält verschiedene Tests die dein Implementation prüfen. Sorge dafür, dass diese Tests erfolgreich sind. Stelle dazu sicher, dass die Input-Shapes der Methoden die du implementierst den Doc-Strings entsprechen.\n",
    "\n",
    "**Achtung: Die Tests decken nicht alles ab. Du kannst also nicht davon ausegehen, dass dein Implementation korrekt ist sobald die Tests erfolgreich sind.**\n",
    "\n",
    "Deine Abgabe wird noch mit weiteren, für dich nicht sichtbare Tests, geprüft. Es ist grundsätzlich deine Aufgabe, die Implementation genau zu prüfen. Du kannst dazu weitere Zellen mit eigenen Tests einfügen. Du kannst jedoch die folgende Zelle nicht ändern. Diese wird nach Abgabe wieder überschrieben, sodass die von mir definierten Tests ausgeführt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144abb5-7657-4a4a-880f-ec48340a7f73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f015049551c16c07a29a82e503099d20",
     "grade": true,
     "grade_id": "tests2b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "def print_result(test_name, passed, expected, actual):\n",
    "    status = \"Passed\" if passed else \"Failed\"\n",
    "    print(f\"{status} test: {test_name}\")\n",
    "    print(f\"----> Expected: {expected}\")\n",
    "    print(f\"----> Actual: {actual}\")\n",
    "\n",
    "\n",
    "def run_test_multivariate():\n",
    "    Xdummy, ydummy, w_true = make_regression(\n",
    "        n_samples=30, bias=5.0, coef=True, n_features=2, n_targets=1, random_state=123\n",
    "    )\n",
    "    w_true = np.concatenate([np.array([5.0]), w_true])\n",
    "\n",
    "    lr = LinearRegression(alpha=0, epsilon=1e-3, optimization_method=\"bgd\", learning_rate=0.1)\n",
    "    lr.fit(Xdummy, ydummy)\n",
    "\n",
    "    try:\n",
    "        np.testing.assert_allclose(w_true, lr.w_, atol=1e-3)\n",
    "        print_result(\"run_test_multivariate\", True, w_true, lr.w_)\n",
    "    except AssertionError:\n",
    "        print_result(\"run_test_multivariate\", False, w_true, lr.w_)\n",
    "\n",
    "\n",
    "def run_test_univariate():\n",
    "    Xdummy, ydummy, w_true = make_regression(\n",
    "        n_samples=30, bias=5.0, coef=True, n_features=1, n_targets=1, random_state=123\n",
    "    )\n",
    "    w_true = np.concatenate([np.array([5.0]), np.array([w_true])])\n",
    "    \n",
    "    lr = LinearRegression(alpha=0, epsilon=1e-3, optimization_method=\"bgd\", learning_rate=0.1)\n",
    "    lr.fit(Xdummy, ydummy)\n",
    "    try:\n",
    "        np.testing.assert_allclose(w_true, lr.w_, atol=1e-3)\n",
    "        print_result(\"run_test_univariate\", True, w_true, lr.w_)\n",
    "    except AssertionError:\n",
    "        print_result(\"run_test_univariate\", False, w_true, lr.w_)\n",
    "\n",
    "\n",
    "def run_test_score():\n",
    "    Xdummy, ydummy, w_true = make_regression(\n",
    "        n_samples=30, bias=5.0, coef=True, n_features=1, n_targets=1, random_state=123\n",
    "    )\n",
    "    lr = LinearRegression(alpha=0, epsilon=1e-3, optimization_method=\"bgd\", learning_rate=0.1)\n",
    "    lr.fit(Xdummy, ydummy)\n",
    "    score = lr.score(Xdummy, ydummy)\n",
    "    expected_score = 1.0\n",
    "\n",
    "    try:\n",
    "        np.testing.assert_almost_equal(score, expected_score, decimal=3)\n",
    "        print_result(\"run_test_score\", True, expected_score, score)\n",
    "    except AssertionError:\n",
    "        print_result(\"run_test_score\", False, expected_score, score)\n",
    "\n",
    "\n",
    "def run_test_cost():\n",
    "    Xdummy, ydummy, _ = make_regression(\n",
    "        n_samples=30, bias=5.0, coef=True, n_features=1, n_targets=1, random_state=123\n",
    "    )\n",
    "    lr = LinearRegression(alpha=0, epsilon=1e-3, optimization_method=\"bgd\", learning_rate=0.1)\n",
    "    lr.fit(Xdummy, ydummy)\n",
    "    actual_cost = lr.cost(Xdummy, ydummy)\n",
    "    expected_cost = 1e-6\n",
    "\n",
    "    try:\n",
    "        assert actual_cost < expected_cost\n",
    "        print_result(\"run_test_cost\", True, f\"< {expected_cost}\", actual_cost)\n",
    "    except AssertionError:\n",
    "        print_result(\"run_test_cost\", False, f\"< {expected_cost}\", actual_cost)\n",
    "\n",
    "\n",
    "def run_test_gradient():\n",
    "\n",
    "    Xdummy, ydummy, w_true = make_regression(\n",
    "        n_samples=30, bias=5.0, coef=True, n_features=1, n_targets=1, random_state=123\n",
    "    )\n",
    "    w_true = np.concatenate([np.array([5.0]), np.array([w_true])])\n",
    "\n",
    "    lr = LinearRegression(alpha=0, epsilon=1e-3, optimization_method=\"bgd\", learning_rate=0.1)\n",
    "    lr = lr.fit(Xdummy, ydummy)\n",
    "    \n",
    "    expected_gradient = np.array([-6.92655851, -59.01320294])\n",
    "    weights = np.array([0.0, 0.0])\n",
    "    lr.w_ = weights\n",
    "    actual_gradient = lr.gradient(Xdummy, ydummy)\n",
    "    try:\n",
    "        np.testing.assert_allclose(actual_gradient, expected_gradient)\n",
    "        print_result(\"run_test_gradient\", True, expected_gradient, actual_gradient)\n",
    "    except AssertionError:\n",
    "        print_result(\"run_test_gradient\", False, expected_gradient, actual_gradient)\n",
    "\n",
    "\n",
    "for test in [run_test_multivariate, run_test_univariate, run_test_score, run_test_cost, run_test_gradient]:\n",
    "    try:\n",
    "        test()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing - test: {test} error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a98ee4-abdf-4348-99aa-ade862fac967",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c005fe1ccd95634c283cf4abf052d562",
     "grade": false,
     "grade_id": "aufgabe2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 2c\n",
    "\n",
    "Erkläre, was die Tests in Aufgabe 2b jeweils prüfen.  \n",
    "\n",
    "Kannst du dir noch weitere Tests vorstellen? Welche?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8adaf94-ab6b-481c-86f5-11e37ce0cf8e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9620861d07bbf1c9e8ea42058952b1b",
     "grade": true,
     "grade_id": "antwort2c",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. multivariate: es wird überprüft ob das Modell mit zwei Features korrekt funktioniert und läuft\n",
    "\n",
    "2. univariate: hier wird geprüft, ob es mit einem Feature funktioniert und läuft\n",
    "\n",
    "3. score: es wird überprüft, ob der R^2-score richtig berechnet wird\n",
    "\n",
    "4. cost: die Kostenfunktion wird überprüft und geschaut, dass sie den gleichen Wert erhält\n",
    "\n",
    "5. gradient: hier wird getestet, ob der gradient richtig implementiert wurde und dementsprechend die gleichen Werte erhält\n",
    "\n",
    "man könnte noch überprüfen, ob die Regularisierung und die verschiedenen Gradient Descent Methoden richtig implementiert wurde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500daaed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11651cd5f5503f517a3478700c9cb7ea",
     "grade": false,
     "grade_id": "aufgabe3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 3 (12 Punkte)\n",
    "\n",
    "In dieser Aufgabe wendest du den Algorithmus auf dem Datensatz `schalentiere_training.csv` an. Damit testest und verwendest du dein Implementation der Klasse `LinearRegression` und lernst gleichzeitig den Datensatz besser kennen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22e2d2-b8e1-4d1f-bb23-523255ba51ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ecbaa1de9d9231dc862601beb4c2295",
     "grade": false,
     "grade_id": "aufgabe3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 3a\n",
    "\n",
    "1) Trainiere ein Modell. Verwende ausschliesslich `laenge` als Input-Variable um `ringe` vorherzusagen. Lass die Variablen komplett unverändert.\n",
    "2) Berechne $R^2$ mit der `score()` Methode und gib den berechneten Wert aus.\n",
    "4) Zeige in einer Tabelle für die ersten 10 Beobachtungen: `y_true` ($\\mathbf{y}$), `y_hat` ($\\mathbf{\\hat{y}}$)und `y_true - y_hat` (das Residuum $\\mathbf{r}$). Erstelle ein `pd.DataFrame` und zeige dieses mit `print` an.\n",
    "5) Berechne und zeige den Wert der Kostenfunktion nach dem Optimieren der Koeffizienten mit Gradient Descent.\n",
    "6) Gib die Modellkoeffizienten aus. Überprüfe die Korrektheit der mit Gradient Descent berechneten Koeffizienten durch Verwendung der Normalengleichung.\n",
    "\n",
    "Verwende `print()` Statements um Fragen nach bestimmten Outputs zu beantworten. Beispiel:\n",
    "\n",
    "```\n",
    "print(f\"R^2 is: {lr.score(X_train, y_train):.3f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55f444-1530-4013-831d-ed088afb4709",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba86dfc730b9e59b5a6e9918ad36d6f4",
     "grade": true,
     "grade_id": "antwort3a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model mit nur laenge und ringe\n",
    "X = data[['laenge']].values\n",
    "y = data['ringe'].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecf419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 score\n",
    "score = lr.score(X, y)\n",
    "print(f\"R^2: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c109bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabelle y_true, y_hat, error\n",
    "y_hat = lr.predict(X)\n",
    "error = y - y_hat\n",
    "results = pd.DataFrame({'y_true': y, 'y_hat': y_hat, 'error': error})\n",
    "print(results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kostenfunktion\n",
    "cost = lr.cost(X, y)\n",
    "print(f\"Cost: {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671cb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellkoefizienten\n",
    "print(f\"Modellkoefizienten: {lr.w_}\")\n",
    "\n",
    "# mit Normalengleichung überprüfen\n",
    "X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "w = np.linalg.inv(X_bias.T @ X_bias) @ X_bias.T @ y\n",
    "print(f\"Modellkoefizienten (Normalgleichung): {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674b972-86a3-4743-ac98-fae1339c0a8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20ffc6836dc8a88771ce450282a1a868",
     "grade": false,
     "grade_id": "aufgabe3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 3b\n",
    "\n",
    "Zeichne einen Tukey-Anscombe-Plot für ihr Modell aus Aufgabe 3a.  \n",
    "\n",
    "Schau dir das Skript von Stahel in den Lernmaterialien dazu an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ec739-52a5-475d-806c-0c0ce4cef291",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e46575616f6c61d2df948bb7cf4889c5",
     "grade": true,
     "grade_id": "antwort3b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tukey Anscombe Plot\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.residplot(x=y_hat, y=error, scatter_kws={'alpha':0.7, 's':50})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.xlabel('Vorhersage Ringe', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Residuen', fontsize=14, labelpad=10)\n",
    "plt.title('Tukey-Anscombe Plot', fontsize=16, pad=15)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c285dd-2902-4e8d-8a54-121d52757b66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d15a9ba863b633c051fd3562aaf3bd00",
     "grade": false,
     "grade_id": "aufgabe3b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Überprüfe die Modell-Annahmen eines linearen Modells durch Analyse der Darstellung. Was schliesst du daraus? Erkläre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed822f-c632-46e5-b99f-989f58acc3b6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48fabbc0a6cc65a851a0d1428fbd8801",
     "grade": true,
     "grade_id": "answer3b2",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1. Linearität von X und Y: Die Residuen zeigen ein Muster und verlaufen in parallelen Linien. Das weist darauf hin, dass X und Y nicht linear zueinander sind. Hier wäre es sinnvoll, eine Transformation der Variablen durchzuführen. \n",
    "\n",
    "2. Unabhängigkeit der Residuen: Man kann davon ausgehen, dass die Residuen unabhängig voneinander sind, da es keine klare Sequenzierung der Residuen giobt. Um diese Annahme jedoch genauer zu überprüfen, sind wietere Tests notwendig (Autokorrelationstests).\n",
    "\n",
    "3. Erwartubgswert = 0: Die Residuen sind in etwa gleichmässig um den Nullpunkt verteilt, jedoch zeigt der Plot Heteroskedastizität. Die Streuung der residuen nimmt mit den Vorhersagewerten zu, was bedeutet, dass die Varianz der Residuen nicht konstant ist. Die Residuen sind also nicht normalverteilt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a3b8f-3374-435e-a090-4f4f735ecafa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8ab637caf37f896696893595abab898",
     "grade": false,
     "grade_id": "aufgabe3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 3c\n",
    "\n",
    "Nimm am Datensatz von Aufgabe 3a geeignete Transformationen vor und fitte die Daten erneut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9be62-c650-45f1-87df-b31980f8dbed",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c371f7d4cbe21c44a42496d00a9a9770",
     "grade": true,
     "grade_id": "answer3c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# geeignete Transformation (logarithmisch)\n",
    "y_log = np.log(data['ringe'].values)\n",
    "\n",
    "# Modell trainieren\n",
    "lr_trans = LinearRegression()\n",
    "lr_trans.fit(X, y_log)\n",
    "\n",
    "# R^2 score\n",
    "score = lr_trans.score(X, y_log)\n",
    "print(f\"R^2: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ee7bd-f11f-4684-8e43-cd1f5f19e493",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4fc656107e9316c69c8f861d7da4482",
     "grade": false,
     "grade_id": "task3c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Überprüfe erneut die Modell-Annahmen mit einem Tukey-Anscombe-Plot.\n",
    "Sind sie nun besser erfüllt?  \n",
    "\n",
    "Ist es ok, das Bestimmtheitsmass mit und ohne Transformation miteinander zu vergleichen?  \n",
    "Begründe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey Anscombe Plot\n",
    "y_log_hat = lr_trans.predict(X)\n",
    "error = y_log - y_log_hat\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.residplot(x=y_log_hat, y=error, scatter_kws={'alpha':0.7, 's':50})\n",
    "plt.xlabel('Vorhersage Ringe', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Residuen', fontsize=14, labelpad=10)\n",
    "plt.title('Tukey-Anscombe Plot', fontsize=16, pad=15)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec7026-4d7c-4987-97f6-bf570ac848d4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fa955ab3db81dbd180cd28778a7cf6f",
     "grade": true,
     "grade_id": "answer3c2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1. Der Plot sieht nun etwas besser aus, jedoch gibt es immer noch systematische Muster (bei den grösseren Ringen jedoch nicht mehr so stark). Die Residuen haben ebenfalls noch eine leichte Asymmetrie, was beduetet, dass sie immer noch nicht komplett normalverteilt sind. Im Vergleich zu anderen Transformationen (Quadratische, Quadrierte Transformation) ist diese am geeignetsten.\n",
    "\n",
    "2. Das Bestimmheitsmass beider Regresionen miteinander zu vergleichen ist nicht besonders sinnvoll, denn es bezieht sich auf die Skalierung und Verteilung der abhängigen Variable. Bei einer Transformation verändert sich die abhängige Variable und somit auch die Verteilung der Daten, bei einer logarithmischen Transformation werden grosse Werte zum Beispiel weniger gewichtet, was das das Ergebnis verzerrt. Ein hoher R²-Wert auf der transformierten Skala bedeutet nicht unbedingt eine bessere Modellanpassung auf der ursprünglichen Skala, da durch die Transformation die Struktur der Daten und damit das Gewicht der Fehler verändert wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a982022-7110-40ec-9358-216b384039fd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83408e1e6b43d2403b6f515a5b95d93f",
     "grade": false,
     "grade_id": "aufgabe4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 4 (14 Punkte)\n",
    "\n",
    "Erweitere dein Modell aus Aufgabe 3c nun mit den verbleibenden quantitativen unabhängigen Variablen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7759fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle quantitativen Variablen\n",
    "X = data[['gew_s', 'breite', 'laenge', 'gew_tot', 'hoehe', 'gew_i', 'gew_f']].values\n",
    "y = np.log(data['ringe'].values)\n",
    "\n",
    "# Modell trainieren\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# R^2 score\n",
    "score = model.score(X, y)\n",
    "print(f\"R^2: {score}\")\n",
    "\n",
    "# Kostenfunktion\n",
    "cost = model.cost(X, y)\n",
    "print(f\"Cost: {cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22600d64-0731-42a7-a975-70e4bbbab940",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2216b28505329f7c05c2fed0a18d75ce",
     "grade": false,
     "grade_id": "aufgabe4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 4a\n",
    "Trainiere mit dem erweiterten Datensatz zwei Modelle. Einmal mit `optimization_method=\"sgd\"` und einmal mit `optimization_method=\"bgd\"`. Du kannst die restlichen Parameter selber wählen, sie sollen aber identisch sein für die beiden Modelle.\n",
    "\n",
    "Zeichne für beide Modelle eine Learning-Curve. Wähle eine Darstellung die einen einfachen Vergleich erlaubt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dae2b5-19b3-4604-90c6-db3347a0e75f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6eb55979ab7903b1f5fb73af2d72e4f5",
     "grade": true,
     "grade_id": "antwort4a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# SGD Modell\n",
    "model_sgd = LinearRegression(max_num_steps=1000, learning_rate=0.1, optimization_method='sgd', verbose=False)\n",
    "model_sgd.fit(X, y)\n",
    "\n",
    "# BGD Modell\n",
    "model_bgd = LinearRegression(max_num_steps=1000, learning_rate=0.1, optimization_method='bgd', verbose=False)\n",
    "model_bgd.fit(X, y)\n",
    "\n",
    "# Plot der Learning-Curves für beide Modelle\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.plot(model_sgd.costs_, label='SGD')\n",
    "ax1.plot(model_bgd.costs_, label='BGD')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Cost')\n",
    "ax1.legend()\n",
    "ax1.set_title('Gesamter Kostenverlauf: SGD vs. BGD')\n",
    "\n",
    "ax2.plot(model_sgd.costs_, label='SGD')\n",
    "ax2.plot(model_bgd.costs_, label='BGD')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Cost')\n",
    "ax2.legend()\n",
    "ax2.set_title('Zoom auf Kostenverlauf: SGD vs. BGD')\n",
    "ax2.set_xlim(0, 1000) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3018cb-4c48-45f8-b06a-0276beeac121",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e26f270bba4d029e1d04a597672e1f11",
     "grade": false,
     "grade_id": "aufgabe4a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Wie unterscheiden sich die Learning-Curves? Warum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c95aa-329e-428b-8250-fb5ea1b80ac5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0bb5f8614ce96f7457991efb9f10825",
     "grade": true,
     "grade_id": "antwort4a2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. BGD: Hier wird der Gradient bei jeder Iteration anhand aller Datenpunkte berechnet, somit zeigt die Lernkurve eine gleichmässige Abnahme der Kostenfunktion. Die Berechnung des Minima benötigt jedoch mehrere Iterationen, wodurch die Berechnung länger dauert. Wir erreichen hier eine präzise Konvergenz zum globalen Minimum, allerdings nur, wenn es genügend Iterationsschritte gibt.\n",
    "\n",
    "2. SGD: Hier wird der Gradient mit nur einem zufällig ausgewählten Datenpunkt geschätzt, was zu diesen grossen Schwankungen in der Lernkurve führt. Die Berechnung des Minima benötigt weniger Iterationen, wodurch die Berechnung schneller geht. Wir befinden uns hier im Bereich des globalen Minimum, das Modell bleibt oft nur in der Nähe des Minimum, ohne es genau zu erreichen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e7a01-67a9-421a-874a-32695fddef42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75e5f196821b0f88d76274e190db062c",
     "grade": false,
     "grade_id": "aufgabe4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 4b\n",
    "\n",
    "Gib die Koeffizienten und das Bestimmheitsmass der Lösungen der beiden Gradient Descent Methoden aus und vergleiche sie mit der Lösung, welche du via Normalengleichung berechnest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247606f6-4570-4a2c-9e4e-abe904ae8fed",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2593713dfe134f55e291c48ed9bea2a8",
     "grade": true,
     "grade_id": "antwort4b",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Koeffizienten und Bestimmtheitsmass\n",
    "print(f\"SGD Modellkoefizienten: {model_sgd.w_}\")\n",
    "print(f\"SGD R^2: {model_sgd.score(X, y)}\")\n",
    "\n",
    "print(f\"BGD Modellkoefizienten: {model_bgd.w_}\")\n",
    "print(f\"BGD R^2: {model_bgd.score(X, y)}\")\n",
    "\n",
    "# Vergleich mit Normalengleichung\n",
    "X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "w = np.linalg.inv(X_bias.T @ X_bias) @ X_bias.T @ y\n",
    "print(f\"Modellkoefizienten (Normalgleichung): {w}\")\n",
    "print(f\"R^2 (Normalgleichung): {1 - np.sum((y - X_bias @ w)**2) / np.sum((y - np.mean(y))**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cedea7-b525-4413-a1dc-c917f407b415",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63391f009c7cf69321f62e2370f05c7b",
     "grade": false,
     "grade_id": "aufgabe4b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Was stellst du fest? Wie interpretierst und erklärst du das Beobachtete?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2a1e3-983e-4109-878d-67636619443a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "318660a28f3deb5913ad535055a2e027",
     "grade": true,
     "grade_id": "answer4b2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1. Modellkoefizienten: Die Normalengleichung und der BGD haben die geringste durchschnittliche Abweichung von 0.05, somit hat der BGD eine präzisere Annäherung an das Optimum als der SGD. Dies erklärt sich dadurch, dass die Berechnung des Optimum beim SGD nicht so genau ist wie beim BGD.\n",
    "\n",
    "2. Bestimmtheitsmass: Der R²-Wert ist bei der Normalengleichung und dem BGD fast identisch und die des SGD leicht schlechter. Dies bestätigt also nochmals, dass der SGD weniger präziser ist (jedoch um einiges schneller bei grossen Datenmengen)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18514e51-b633-425a-ace8-97bb65f1593f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "feb51f4ef013df929ac9dd74b1b3a4e9",
     "grade": false,
     "grade_id": "aufgabe4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 4c\n",
    "\n",
    "Nun untersuchen wir verschiedene Learning-Rates. Verwende dasselbe Setup wie in Aufgabe 4b. Mit folgenden Parameter:\n",
    "\n",
    "- `epsilon=-1`\n",
    "- `alpha=0`\n",
    "- `optimization_method=\"bgd\"`\n",
    "- `max_num_steps=500`\n",
    "\n",
    "Variiere ausschliesslich den `learning_rate` Parameter in einem sinnvollen Bereich. Wähle mind. 10 verschiedene Werte. Trainiere mehrere Modelle und vergleiche die Konvergenz der Modelle für jeden Wert von `learning_rate`. Versuche eine möglichst hohe, funktionierende Learning-Rate zu finden. Zeichne dazu die Learning-Curves in eine Figure.\n",
    "\n",
    "Achte darauf, dass die Darstellung einen sinnvollen Vergleich erlaubt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b85f52-912e-4041-8c34-fa2ca8ab9e89",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0639de6253b48566d122a78d328ee9f7",
     "grade": true,
     "grade_id": "antwort4c",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.2, 0.3, 0.5, 0.7, 0.01, 0.02, 0.05, 0.07, 0.001]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "legend = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = LinearRegression(epsilon=-1, alpha=0, max_num_steps=500, learning_rate=lr, optimization_method='bgd')\n",
    "    model.fit(X, y)\n",
    "    r2_score = model.score(X, y)\n",
    "    plt.plot(model.costs_) \n",
    "    legend.append(f\"lr={lr}, R²={r2_score:.3f}\")\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend(legend)\n",
    "plt.title('Kostenverlauf für verschiedene Lernraten')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592d46b-20e5-4ac5-9e4e-fd05549b5a00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2015fc75e75f34cda4760f3cd148550b",
     "grade": false,
     "grade_id": "aufgabe4c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Interpretiere die Learning-Curves. Was siehst du? Welche Learning-Rates funktionieren und sind praktikabel? Welche findest du optimal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff373323-cf17-4df7-935a-9ac9cc9554fc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "609553ae45251702501d02c76ef3d80b",
     "grade": true,
     "grade_id": "antwort4c2",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Die Learning-Rates 0.5, 0.7 sind die besten geeignet, da sie eine schnelle Konvergenz zeigen und die Kostenfunktion am schnellsten minimieren. Jedoch kann es bei hohen Learning-Rates zu Oszillationen oder Instabilität führen, also dass das Modell nicht konvergiert. Generell ist es wichtig, die Learning-Rate so zu wählen, dass die Kostenfunktion schnell minimiert wird, aber auch stabil bleibt. Da alle ausser 0.001 zu einem relativ schnellen Konvergenz führen, sind diese auch praktikabel. \n",
    "Für mich ist die Learning-rate 0.3 optimal, da sie eine schnelle Konvergenz zeigt und Oszillationen vermeidet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4366a78-fec0-4359-81cb-f1f6967677ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf0440bb9b1bd463e25705d9a0809356",
     "grade": false,
     "grade_id": "aufgabe5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 5 (3 Punkte)\n",
    "\n",
    "Füge die Variable `geschlecht` hinzu. Fitte ein neues unregularisiertes Lineares Modell.  \n",
    "\n",
    "Erstelle erneut einen Tukey-Anscombe-Plot.\n",
    "\n",
    "Miss das Bestimmtheismass nun auch auf den Testdaten `schalentiere_test.csv`.\n",
    "\n",
    "Tipp: Du kannst von `sklearn.preprocessing` `StandardScaler` und `OneHotEncoder`, sowie `sklearn.compose.ColumnTransformer` und `sklearn.pipeline.Pipeline`verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50060ea-c742-42ef-a54f-3a0ca8076437",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a480aa2edb8379838ba17febce1c6e5",
     "grade": true,
     "grade_id": "antwort5",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Geschlecht hinzufügen\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# M zu 0, W zu 1\n",
    "data['geschlecht'] = data['geschlecht'].map({'M': 0, 'W': 1})\n",
    "\n",
    "data_test = pd.read_csv('schalentiere_test.csv')\n",
    "data_test['geschlecht'] = data_test['geschlecht'].map({'M': 0, 'W': 1})\n",
    "\n",
    "X_test = data_test[['gew_s', 'breite', 'laenge', 'gew_tot', 'hoehe', 'gew_i', 'gew_f', 'geschlecht']]\n",
    "y_test = np.log(data_test['ringe'].values)\n",
    "\n",
    "X = data[['gew_s', 'breite', 'laenge', 'gew_tot', 'hoehe', 'gew_i', 'gew_f', 'geschlecht']]\n",
    "y = np.log(data['ringe'].values)\n",
    "\n",
    "# Modell trainieren\n",
    "model = Pipeline([\n",
    "    ('regressor', LinearRegression(learning_rate=0.3))\n",
    "])\n",
    "\n",
    "model.fit(X, y)\n",
    "print(f\"R^2: {model.score(X, y)}\")\n",
    "\n",
    "# Tukey-Anscombe Plot\n",
    "y_hat = model.predict(X)\n",
    "error = y - y_hat\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.residplot(x=y_hat, y=error, scatter_kws={'alpha':0.7, 's':50})\n",
    "plt.xlabel('Vorhersage Ringe', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Residuen', fontsize=14, labelpad=10)\n",
    "plt.title('Tukey-Anscombe Plot', fontsize=16, pad=15)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "# Bestimmtheitsmass Testdaten\n",
    "r2_test = model.score(X_test, y_test)\n",
    "print(f\"R^2 Testdaten: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17208d8-8a2e-4aeb-9f3f-141a56457d56",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d11078b9ca81d8e76ad1a21a43205b20",
     "grade": false,
     "grade_id": "aufgabe5_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Wie interpretierst du den Tukey-Anscombe-Plot?\n",
    "\n",
    "Vergleiche das neue Modell, sämtlicher unabhängiger Variablen mit der Lösung aus Aufgabe 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf48bf0f",
   "metadata": {},
   "source": [
    "Im Vergleich zum Tukey-Anscombe-Plot aus Aufgabe 4 zeigt das Modell eine leicht verbesserte Anpassung. Die Residuen sind nun gleichmässiger um den Nullpunkt verteilt, die Varianz hat also abgenommen. Beide Modelle haben jedoch noch systematische Muster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33734bf-a923-465a-9138-fb349fa59fd7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ef2c43218a4f85871a2b88c563d7362",
     "grade": false,
     "grade_id": "aufgabe6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 6 (5 Punkte)\n",
    "\n",
    "Untersuche nun den Effekt der Regularisierung $\\lambda$ (Parameter `alpha`) auf das Modell. Dazu trainierst du mehrere Modelle mit verschiedenen Werten von `alpha` und vergleichst dann die Resultate. Folgende Bedingungen sollst du erfüllen:\n",
    "\n",
    "- Wähle die `alpha` über einen grosszügig gewählten Bereich. Alle anderen Parameter sollen für alle Modelle identisch sein.\n",
    "- Vergleiche für die verschiedenen Modelle die gefundenen Modell-Koeffizienten $\\mathbf{w}$. Plotte dazu `alpha` auf der X-Achse und den Wert von jedem Modell-Koeffizient auf der Y-Achse. Beispiel: [Link](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_path.html)\n",
    "\n",
    "Am Besten verwendest du dazu erneut eine scikit-learn Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d99e9-0c24-49e5-a3a9-0824ce9088a9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca1c3f100a5ef44721062f35d70081b1",
     "grade": true,
     "grade_id": "antwort6",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-5, 4, 20)\n",
    "\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    model = LinearRegression(alpha=a, epsilon=-1, optimization_method=\"bgd\", learning_rate=0.3, max_num_steps=500, verbose=False)\n",
    "    model.fit(X, y)\n",
    "    coefs.append(model.w_)\n",
    "\n",
    "# Plot der Koeffizienten\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"weights\")\n",
    "plt.title(\"Regularization Path\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bf08a7-8721-4df0-981a-83a497c477b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "893852cf38cdf1c1dae5f26acb8b42d5",
     "grade": false,
     "grade_id": "aufgabe6_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Interpretiere den Plot. Was sieht man und warum sieht es so aus?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf170e",
   "metadata": {},
   "source": [
    "In diesem Plot erkennt man die Veränderung der Koeffizienten in Abhängigkeit der Regularisierung. Je höher die Regularisierung, desto stärker werden die Koeffizienten reduziert. Dies ist sinnvoll, da die Regularisierung die Koeffizienten reduziert, um Overfitting zu verhindern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-distinction",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e747dc643164dc7dbae90429770c4f6a",
     "grade": false,
     "grade_id": "aufgabe7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 7 (7 Punkte)\n",
    "\n",
    "In dieser Aufgabe geht es nun darum, ein bestmögliches lineares Regressions-Modell zu finden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab08236",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49e3b4749527d2db7c74a02d199af131",
     "grade": false,
     "grade_id": "aufgabe7a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 7a\n",
    "\n",
    "- Entwickle nun ein multiples lineares Regressionsmodell für die Zielgrösse `ringe`.\n",
    "- Du darfst dazu auch weitere Features hinzufügen, beispielsweise mit dem `PolynomialFeatures`-Transformer.\n",
    "- Trainiere das Modell mit dem Trainings-Datensatz. \n",
    "- Evaluiere das beste Modell auf dem Trainings- und auf dem Testdatensatz.\n",
    "\n",
    "Hinweis: In dieser Aufgabe geht es darum ein möglichst gutes Modell zu finden. Du sollst demonstrieren, dass du in der Lage bist, verschiedene Modell-Varianten miteinander zu vergleichen und die beste Variante auszuwählen. Ein ideales Instrument ist Kreuzvalidierung. Lies dazu die folgende Dokumentation: [cross_validation](https://scikit-learn.org/stable/modules/cross_validation.html). Verwende [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) um verschiedene Modelle miteinander zu vergleichen. \n",
    "\n",
    "Verwende weitere geeignete Instrumente von sklearn, wie z.B.:\n",
    "- [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "- [sklearn.pipeline.Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "- [sklearn.compose](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.compose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fccd5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b4223776759c99eea5a6eb04f14fb15",
     "grade": true,
     "grade_id": "answer7a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Multiple Regression mit Polynom\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('poly', PolynomialFeatures()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), slice(0, X.shape[1]))\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression(optimization_method='bgd', max_num_steps=500, learning_rate=0.3, verbose=False))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__num__poly__degree': [1, 2, 3],\n",
    "    'regressor__alpha': np.logspace(-3, 3, 7) \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4628b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6193c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdaten\n",
    "best_model = grid_search.best_estimator_\n",
    "r2_test = best_model.score(X_test, y_test)\n",
    "print(f\"R^2 Testdaten: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118c0d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0dea34023520ae36033d8dfbd71e3d9c",
     "grade": false,
     "grade_id": "aufgabe7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 7b\n",
    "\n",
    "Interpretiere das Ergebnis:\n",
    "\n",
    "- Welche Modell-Varianten hast du verglichen? Welche ist die beste?\n",
    "- Vergleiche und interpretiere die Scores auf Test- und Trainingsdatensatz. Wie schneidet das Modell im Vergleich zum Modell aus Aufgabe 5 ab?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b10e20",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "803a48a3caad00e6a1e9f3eb040f7108",
     "grade": true,
     "grade_id": "answer7b",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1. Ich habe den Polynomgrad und Regularisierungsparameter varrieriert und die Modelle miteinander verglichen. Das beste Modell ist das Modell mit einem Polynomgrad von 1 und einem Regularisierungsparameter von 0.001. \n",
    "\n",
    "2. Der Score von 0.568 auf dem Trainingsdatensatz ist der beste Kreuzvalidierungsscore, bei der Wahl der besten Hyperparameter. Der Score auf dem Trainingsdatensatz beträgt ähnlich viel (0.584), was darauf hindeutet, dass das Modell gut generalisiert. Da die Parameter im vergleichb zu Aufgabe 5 gleich sind, schneiden die beiden Modelle auch gleich ab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c37f898-0e77-4a63-b93d-4b4ae6aff65d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41b3a231a5d375c79f01a10c7d31dd7d",
     "grade": false,
     "grade_id": "aufgabe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 8 (11 Punkte)\n",
    "\n",
    "In dieser Aufgabe vergleichen wir die Ridge Regression mit Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd29810-8e9d-428c-8dc6-93860f40dd75",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "615481e14621e31ea328490d83c5cbb1",
     "grade": false,
     "grade_id": "aufgabe8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 8a\n",
    "\n",
    "Wie unterscheiden sich Lasso und Ridge regression hinsichtlich ihrer Kostenfunktionen?  \n",
    "\n",
    "Was hat dies für Konsequenzen für die Optimierung der Modell-Koeffizienten?  \n",
    "\n",
    "Wie unterscheiden sich die Lösungen typischerweise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887d984",
   "metadata": {},
   "source": [
    "- Ridge-Regression\n",
    "\n",
    "Die Kostenfunktion der Ridge-Regression mit einer \\( L_2 \\)-Strafe lautet:\n",
    "\n",
    "$$\n",
    "J(\\beta) = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2\n",
    "$$\n",
    "\n",
    ">Die Koeffizienten werden klein, aber werden nicht auf null gesetzt, den Einfluss der Koeffizienten wird also nur verringert (kugelförmig).\n",
    "\n",
    "- Lasso-Regression\n",
    "\n",
    "Die Kostenfunktion der Lasso-Regression mit einer \\( L_1 \\)-Strafe lautet:\n",
    "\n",
    "$$\n",
    "J(\\beta) = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^p |\\beta_j|\n",
    "$$\n",
    "\n",
    ">Die Koeffizienten werden hier auf genau 0 gesetzt, es haben dann also nicht mehr alle Variablen einen Einfluss auf das Modell, nur die wichtigsten Variablen bleiben (Diamantförmig)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1aaa1f-ff8a-4c8e-aeca-a532c7a5978c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00bc8d141973b085d1de1c2c9c1c046d",
     "grade": false,
     "grade_id": "aufgabe8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 8b\n",
    "\n",
    "Untersuche deine Vermutungen aus Aufgabe 8a zu den Lösungseigenschaften von Lasso durch Zeichnen des Lasso-Pfades.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8111eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso-Pfad zeichnen\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alphas = np.logspace(-5, 4, 20)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    model = Lasso(alpha=a, max_iter=500)\n",
    "    model.fit(X, y)\n",
    "    coefs.append(model.coef_)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"weights\")\n",
    "plt.title(\"Lasso Path\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df2ef54-5de1-45fc-bb5e-1b6966ad3e47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee2158a06ed9425e534d114bc9e1ef56",
     "grade": false,
     "grade_id": "aufgabe8b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Findest du deine Vermutungen bestätigt? Erkläre dies anhand des Plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8397a0",
   "metadata": {},
   "source": [
    "Ja der Plot bestätigt die Vermutungen, für hohe Werte von lambda sind fast alle Koeffizienten auf null gesetzt. Man erkennt, dass nur eine sehr gerine Regularisierung notwendig ist, um die Koeffizienten auf null zu setzen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee6cb9-5f9d-44d3-8e68-b54e91dfeed8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db140b5825158a361f900ac6f4c2947f",
     "grade": false,
     "grade_id": "aufgabe8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 8c\n",
    "\n",
    "Finde nun das beste Lasso-Modell.\n",
    "\n",
    "Bespreche dein Resultat.\n",
    "\n",
    "Gehe dazu gleich vor wie in Aufgabe 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1727b3-c0be-476d-89a5-b1de265f3621",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "117876f2ea4169adb7db610212a83ea3",
     "grade": true,
     "grade_id": "antwort8c",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# bestes Lasso-Modell finden mit polynom und cross-validation\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('poly', PolynomialFeatures()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), slice(0, X.shape[1]))\n",
    "    ], \n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso(max_iter=500))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__num__poly__degree': [1, 2, 3],\n",
    "    'regressor__alpha': np.logspace(-3, 1, 20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdaten\n",
    "best_model = grid_search.best_estimator_\n",
    "r2_test = best_model.score(X_test, y_test)\n",
    "print(f\"R^2 Testdaten: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc9b65-7069-47af-a49e-3d6184eee93a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f81ca967c0dbb212e0f6d8a443b19b63",
     "grade": true,
     "grade_id": "antwort8c2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Wir haben hier ein Modell mit einem Polynomgrad von 2 und einem Regularisierungsparameter von 0.001. Dieses Modell hat den besten Kreuzvalidierungsscore von 0.621. Der Score auf dem Trainingsdatensatz beträgt ähnlich viel (0.636), was darauf hindeutet, dass das Modell gut generalisiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8e42e-e43a-4c41-9cff-0c2e08d05020",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7c02a8f8e09e78dc2785ef2afed2c36",
     "grade": false,
     "grade_id": "aufgabe9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 9 (4 Punkte)\n",
    "\n",
    "In dieser Aufgabe verwenden wir nun noch k-Nearest-Neighbours als Modellierungsansatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220630bf-2cfd-4912-9d3b-9d31fae110a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d03a70f621da4fadc24ce963ea802629",
     "grade": false,
     "grade_id": "aufgabe9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 9a\n",
    "\n",
    "Finde und bespreche ein bestmögliches k-Nearest-Neighbours-Modell, wieder analog zu Aufgabe 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc006f2-6520-45b3-a7c7-a57232cbad7e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "905361c1e2c22197b9f0551fa6095f39",
     "grade": true,
     "grade_id": "antwort9a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# bestmögliche k-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('poly', PolynomialFeatures()),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), slice(0, X.shape[1]))\n",
    "    ], \n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__num__poly__degree': [1, 2, 3],\n",
    "    'regressor__n_neighbors': [15, 17, 19, 21, 23, 25, 27, 29]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdaten\n",
    "best_model = grid_search.best_estimator_\n",
    "r2_test = best_model.score(X_test, y_test)\n",
    "print(f\"R^2 Testdaten: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22fa38d-6b32-4179-b513-6248665b9e81",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1510b642123a337247673ebcae2307b",
     "grade": true,
     "grade_id": "antwort9a2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Wir haben hier ein Modell mit einem Polynomgrad von 1 und K-Nearest Neighbours von 19. Dieses Modell hat den besten Kreuzvalidierungsscore von 0.60. Der Score auf dem Trainingsdatensatz beträgt ähnlich viel (0.624), was darauf hindeutet, dass das Modell gut generalisiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-grace",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c62a836a058ed79c5c1c144de266161",
     "grade": false,
     "grade_id": "aufgabe10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 10 (2 Punkte)\n",
    "\n",
    "In dieser Aufgabe geht es darum die Ergebnisse der einzelnen Teilaufgaben zu konsolidieren und ein Fazit zu ziehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe0b8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d013c654b180220df405d5f0e1408f84",
     "grade": false,
     "grade_id": "aufgabe10a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 10a\n",
    "\n",
    "Beantworte folgende Fragen:\n",
    "\n",
    "- Wie schätzst du den Modellierungserfolg der verschiedenen Modellierungsansätze ein? Welche sind gut oder schlecht? Begründe dein Antwort.\n",
    "\n",
    "- Wie könntest du herausfinden, welches die wichtigsten Variablen für die Vorhersage sind?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faca3d6-c6be-451c-9299-36ebf1a59af6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d00d9e6ea58ae0305749994044f095b",
     "grade": true,
     "grade_id": "antwort10a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1. Alle Modellierungsansätze haben einen ähnlichen Score, jedoch hat das Modell mit dem Lasso den besten Score. Dieses Modell ist also am besten geeignet, um die Anzahl der Ringe vorherzusagen.\n",
    "\n",
    "2. Um herauszufinden, welche die wichtigsten Variablen sind, ist es sinnvoll, die Koeffizienten der Modelle zu betrachten. Je grösser der Koeffizient, desto wichtiger ist die Variable für die Vorhersage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
